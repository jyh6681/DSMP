{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "315081e1-78bd-4d1e-9fd1-d40ee5327345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import lobpcg\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils import get_laplacian\n",
    "from torch_geometric.nn import GATConv\n",
    "import math\n",
    "import argparse\n",
    "import os.path as osp\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# function for pre-processing\n",
    "@torch.no_grad()\n",
    "def scipy_to_torch_sparse(A):\n",
    "    A = sparse.coo_matrix(A)\n",
    "    row = torch.tensor(A.row)\n",
    "    col = torch.tensor(A.col)\n",
    "    index = torch.stack((row, col), dim=0)\n",
    "    value = torch.Tensor(A.data)\n",
    "\n",
    "    return torch.sparse_coo_tensor(index, value, A.shape)\n",
    "\n",
    "\n",
    "# function for pre-processing\n",
    "def ChebyshevApprox(f, n):  # assuming f : [0, pi] -> R\n",
    "    quad_points = 500\n",
    "    c = np.zeros(n)\n",
    "    a = np.pi / 2\n",
    "    for k in range(1, n + 1):\n",
    "        Integrand = lambda x: np.cos((k - 1) * x) * f(a * (np.cos(x) + 1))\n",
    "        x = np.linspace(0, np.pi, quad_points)\n",
    "        y = Integrand(x)\n",
    "        c[k - 1] = 2 / np.pi * np.trapz(y, x)\n",
    "\n",
    "    return c\n",
    "\n",
    "\n",
    "# function for pre-processing\n",
    "def get_operator(L, DFilters, n, s, J, Lev):\n",
    "    r = len(DFilters)\n",
    "    c = [None] * r\n",
    "    for j in range(r):\n",
    "        c[j] = ChebyshevApprox(DFilters[j], n)\n",
    "    a = np.pi / 2  # consider the domain of masks as [0, pi]\n",
    "    # Fast Tight Frame Decomposition (FTFD)\n",
    "    FD1 = sparse.identity(L.shape[0])\n",
    "    d = dict()\n",
    "    for l in range(1, Lev + 1):\n",
    "        for j in range(r):\n",
    "            T0F = FD1\n",
    "            T1F = ((s ** (-J + l - 1) / a) * L) @ T0F - T0F\n",
    "            d[j, l - 1] = (1 / 2) * c[j][0] * T0F + c[j][1] * T1F\n",
    "            for k in range(2, n):\n",
    "                TkF = ((2 / a * s ** (-J + l - 1)) * L) @ T1F - 2 * T1F - T0F\n",
    "                T0F = T1F\n",
    "                T1F = TkF\n",
    "                d[j, l - 1] += c[j][k] * TkF\n",
    "        FD1 = d[0, l - 1]\n",
    "\n",
    "    return d\n",
    "\n",
    "\n",
    "class GFAConv(nn.Module):\n",
    "    def __init__(self, in_features, out_features, r, Lev, num_nodes, shrinkage=None, threshold=1e-4, bias=True, att_dropout_prob=0.9):\n",
    "        super(GFAConv, self).__init__()\n",
    "        self.Lev = Lev\n",
    "        self.shrinkage = shrinkage\n",
    "        self.threshold = threshold\n",
    "        self.crop_len = (Lev - 1) * num_nodes\n",
    "        if torch.cuda.is_available():\n",
    "            self.weight = nn.Parameter(torch.Tensor(in_features, out_features).cuda())\n",
    "#             self.filter = nn.Parameter(torch.Tensor(r * Lev * num_nodes, 1).cuda())\n",
    "#             self.filter0 = nn.Parameter(torch.Tensor(num_nodes, 1).cuda())\n",
    "            self.filter1 = nn.Parameter(torch.Tensor(num_nodes, 1).cuda())\n",
    "            self.filter2 = nn.Parameter(torch.Tensor(num_nodes, 1).cuda())\n",
    "            self.filter3 = nn.Parameter(torch.Tensor(num_nodes, 1).cuda())\n",
    "        else:\n",
    "            self.weight = nn.Parameter(torch.Tensor(in_features, out_features))\n",
    "            self.filter = nn.Parameter(torch.Tensor(r * Lev * num_nodes, 1))\n",
    "        if bias:\n",
    "            if torch.cuda.is_available():\n",
    "                self.bias = nn.Parameter(torch.Tensor(out_features).cuda())\n",
    "            else:\n",
    "                self.bias = nn.Parameter(torch.Tensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "        # GAT module\n",
    "#         self.GATconv0 = GATConv(out_features, out_features, heads=1, dropout=0.7)\n",
    "        self.GATconv1 = GATConv(out_features, out_features, heads=1, dropout=att_dropout_prob)\n",
    "        self.GATconv2 = GATConv(out_features, out_features, heads=1, dropout=att_dropout_prob)\n",
    "        self.GATconv3 = GATConv(out_features, out_features, heads=1, dropout=att_dropout_prob)\n",
    "\n",
    "\n",
    "    def reset_parameters(self):\n",
    "#         nn.init.uniform_(self.filter, 0.9, 1.1)\n",
    "        nn.init.uniform_(self.filter1, 0.9, 1.1)\n",
    "        nn.init.uniform_(self.filter2, 0.9, 1.1)\n",
    "        nn.init.uniform_(self.filter3, 0.9, 1.1)\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "        if self.bias is not None:\n",
    "            nn.init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, x, edge_index, d_list):\n",
    "        # d_list is a list of matrix operators (torch sparse format), row-by-row\n",
    "        # x is a torch dense tensor\n",
    "        x = torch.matmul(x, self.weight)\n",
    "\n",
    "        # Fast Tight Frame Decomposition\n",
    "#         x0 = torch.sparse.mm(d_list[0], x)\n",
    "        x1 = torch.sparse.mm(d_list[1], x)\n",
    "        x2 = torch.sparse.mm(d_list[2], x)\n",
    "        x3 = torch.sparse.mm(d_list[3], x)\n",
    "#         x1 = torch.sparse.mm(torch.cat(d_list[:2], dim=0), x)\n",
    "#         x2 = torch.sparse.mm(torch.cat(d_list[2:], dim=0), x)\n",
    "#         x = torch.cat((x1, x2),0)\n",
    "        # the output x has shape [r * Lev * num_nodes, #Features]\n",
    "\n",
    "        # perform wavelet shrinkage (optional)\n",
    "        if self.shrinkage is not None:\n",
    "            if self.shrinkage == 'soft':\n",
    "                x = torch.mul(torch.sign(x), (((torch.abs(x) - self.threshold) + torch.abs(torch.abs(x) - self.threshold)) / 2))\n",
    "            elif self.shrinkage == 'hard':\n",
    "                x = torch.mul(x, (torch.abs(x) > self.threshold))\n",
    "            else:\n",
    "                raise Exception('Shrinkage type is invalid')\n",
    "\n",
    "        # Hadamard product in spectral domain\n",
    "#         x = self.filter * x\n",
    "        x11 = self.filter1 * x1\n",
    "        x21 = self.filter2 * x2\n",
    "        x31 = self.filter3 * x3\n",
    "        # filter has shape [r * Lev * num_nodes, 1]\n",
    "        # the output x has shape [r * Lev * num_nodes, #Features]\n",
    "\n",
    "#         # GAT conv in spectral domain\n",
    "#             x12 = F.dropout(F.elu(self.GATconv1(x1, edge_index)), p=0.7, training=self.training)\n",
    "#             x22 = F.dropout(F.elu(self.GATconv2(x2, edge_index)), p=0.7, training=self.training)\n",
    "#             x32 = F.dropout(F.elu(self.GATconv3(x3, edge_index)), p=0.7, training=self.training)\n",
    "#         x0 = self.GATconv1(x0, edge_index)\n",
    "        x12 = self.GATconv1(x1, edge_index)\n",
    "        x22 = self.GATconv2(x2, edge_index)\n",
    "        x32 = self.GATconv3(x3, edge_index)\n",
    "#             x12 = F.dropout(self.GATconv1(x1, edge_index), p=0.2, training=self.training)\n",
    "#             x22 = F.dropout(self.GATconv2(x2, edge_index), p=0.2, training=self.training)\n",
    "#             x32 = F.dropout(self.GATconv3(x3, edge_index), p=0.2, training=self.training)\n",
    "\n",
    "        # Fast Tight Frame Reconstruction\n",
    "#         x = torch.sparse.mm(torch.cat(d_list[self.Lev - 1:], dim=0).transpose(0,1), x[self.crop_len:, :])\n",
    "#         x1 = torch.sparse.mm(torch.cat(d_list[self.Lev - 1:2], dim=0).transpose(0,1), x1[self.crop_len:, :])\n",
    "#         x2 = torch.sparse.mm(torch.cat(d_list[2:], dim=0).transpose(0,1), x2)\n",
    "#         x = x1 + x2\n",
    "        x = torch.sparse.mm(torch.cat([d_list[i] for i in [1, 2, 3]], dim=0).transpose(0,1), torch.cat((x11,x21,x31),0))\\\n",
    "        + torch.sparse.mm(torch.cat([d_list[i] for i in [1, 2, 3]], dim=0).transpose(0,1), torch.cat((x12,x22,x32),0))\n",
    "#         x = torch.cat((torch.sparse.mm(torch.cat([d_list[i] for i in [1, 2, 3]], dim=0).transpose(0,1), torch.cat((x11,x21,x31),0)),\\\n",
    "#         torch.sparse.mm(torch.cat([d_list[i] for i in [1, 2, 3]], dim=0).transpose(0,1), torch.cat((x12,x22,x32),0))), dim=1)\n",
    "        if self.bias is not None:\n",
    "            x += self.bias\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_features, nhid, num_classes, r, Lev, num_nodes, shrinkage=None, threshold=1e-4, dropout_prob=0.5, att_dropout_prob=0.9):\n",
    "        super(Net, self).__init__()\n",
    "        self.GConv1 = GFAConv(num_features, nhid, r, Lev, num_nodes, shrinkage=shrinkage, threshold=threshold, att_dropout_prob=att_dropout_prob)\n",
    "        self.GConv2 = GFAConv(nhid, num_classes, r, Lev, num_nodes, shrinkage=shrinkage, threshold=threshold, att_dropout_prob=att_dropout_prob)\n",
    "        self.drop1 = nn.Dropout(dropout_prob)\n",
    "\n",
    "    def forward(self, x, edge_index, d_list):\n",
    "#         x = data.x  # x has shape [num_nodes, num_input_features]\n",
    "#         edge_index = data.edge_index\n",
    "#             x = F.relu(self.GConv1(x, edge_index, d_list))\n",
    "#             x = self.drop1(x)\n",
    "#             x = self.GConv2(x, edge_index, d_list)\n",
    "        x = self.GConv1(x, edge_index, d_list)\n",
    "        x = self.drop1(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Training on CPU/GPU device\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c53ddfb-e62d-4d8c-8698-aad411691948",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ogb.nodeproppred import Evaluator\n",
    "from torch_geometric.utils import to_undirected, add_self_loops\n",
    "\n",
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "\n",
    "import logging\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2649f981-1f35-45eb-b2ed-0c7780b47408",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(model, x, edge_index, y_true, split_idx, evaluator):\n",
    "    model.eval()\n",
    "    out = model(x, edge_index)\n",
    "\n",
    "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "\n",
    "    train_acc = evaluator.eval({\n",
    "        'y_true': y_true[split_idx['train']],\n",
    "        'y_pred': y_pred[split_idx['train']],\n",
    "    })['acc']\n",
    "    valid_acc = evaluator.eval({\n",
    "        'y_true': y_true[split_idx['valid']],\n",
    "        'y_pred': y_pred[split_idx['valid']],\n",
    "    })['acc']\n",
    "    test_acc = evaluator.eval({\n",
    "        'y_true': y_true[split_idx['test']],\n",
    "        'y_pred': y_pred[split_idx['test']],\n",
    "    })['acc']\n",
    "\n",
    "    return train_acc, valid_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b44b1c1-3e70-47a9-bf66-f4e05affeb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, x, edge_index, y_true, train_idx, optimizer, d_list):\n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    pred = model(x, edge_index, d_list)[train_idx]\n",
    "\n",
    "    loss = F.nll_loss(pred, y_true.squeeze(1)[train_idx])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70e4c89f-5597-4b8f-b743-6253fbcf339b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "# Training on CPU/GPU device\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "dataset = PygNodePropPredDataset(name='ogbn-arxiv')\n",
    "\n",
    "data = dataset[0]\n",
    "split_idx = dataset.get_idx_split()\n",
    "evaluator = Evaluator('ogbn-arxiv')\n",
    "x = data.x.to(device)\n",
    "y_true = data.y.to(device)\n",
    "train_idx = split_idx['train'].to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0d62a93-a7e2-4409-9624-3aa8662182d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes=data.num_nodes\n",
    "edge_index = data.edge_index\n",
    "edge_index = to_undirected(edge_index, data.num_nodes)\n",
    "\n",
    "L = get_laplacian(edge_index, num_nodes=data.num_nodes, normalization='sym')\n",
    "L = sparse.coo_matrix((L[1].numpy(), (L[0][0, :].numpy(), L[0][1, :].numpy())), shape=(num_nodes, num_nodes), dtype='float32')\n",
    "\n",
    "lobpcg_init = np.random.rand(num_nodes, 1)\n",
    "lambda_max, _ = lobpcg(L, lobpcg_init)\n",
    "lambda_max = lambda_max[0]\n",
    "\n",
    "## FrameType = 'Haar'\n",
    "FrameType = 'Haar'\n",
    "if FrameType == 'Haar':\n",
    "    D1 = lambda x: np.cos(x / 2)\n",
    "    D2 = lambda x: np.sin(x / 2)\n",
    "    DFilters = [D1, D2]\n",
    "    RFilters = [D1, D2]\n",
    "elif FrameType == 'Linear':\n",
    "    D1 = lambda x: np.square(np.cos(x / 2))\n",
    "    D2 = lambda x: np.sin(x) / np.sqrt(2)\n",
    "    D3 = lambda x: np.square(np.sin(x / 2))\n",
    "    DFilters = [D1, D2, D3]\n",
    "    RFilters = [D1, D2, D3]\n",
    "elif FrameType == 'Quadratic':  # not accurate so far\n",
    "    D1 = lambda x: np.cos(x / 2) ** 3\n",
    "    D2 = lambda x: np.multiply((np.sqrt(3) * np.sin(x / 2)), np.cos(x / 2) ** 2)\n",
    "    D3 = lambda x: np.multiply((np.sqrt(3) * np.sin(x / 2) ** 2), np.cos(x / 2))\n",
    "    D4 = lambda x: np.sin(x / 2) ** 3\n",
    "    DFilters = [D1, D2, D3, D4]\n",
    "    RFilters = [D1, D2, D3, D4]\n",
    "else:\n",
    "    raise Exception('Invalid FrameType')\n",
    "\n",
    "Lev = 2  # level of transform\n",
    "s = 2  # dilation scale\n",
    "n = 2  # n - 1 = Degree of Chebyshev Polynomial Approximation\n",
    "J = np.log(lambda_max / np.pi) / np.log(s) + Lev - 1  # dilation level to start the decomposition\n",
    "r = len(DFilters)\n",
    "\n",
    "# get matrix operators\n",
    "d = get_operator(L, DFilters, n, s, J, Lev)\n",
    "# enhance sparseness of the matrix operators (optional)\n",
    "# d[np.abs(d) < 0.001] = 0.0\n",
    "# store the matrix operators (torch sparse format) into a list: row-by-row\n",
    "d_list = list()\n",
    "for l in range(Lev):\n",
    "    for i in range(r):\n",
    "        d_list.append(scipy_to_torch_sparse(d[i, l]).float().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70639e59-f3cf-47e0-9813-b59a2de44e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[     0,      0,      0,  ..., 169342, 169342, 169342],\n",
       "                       [167289,  69383,  16718,  ..., 169342, 158981,  27824]]),\n",
       "       values=tensor([2.3229e-04, 1.2885e-04, 1.5486e-04,  ...,\n",
       "                      5.1302e-01, 6.6189e-02, 3.3196e-02]),\n",
       "       device='cuda:1', size=(169343, 169343), nnz=590195053,\n",
       "       dtype=torch.float32, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fa8c33-3dc7-4b60-8bce-3e7ec1d28b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameter Settings\n",
    "\n",
    "search_params = {'learning_rate': 0.0035,\n",
    "                 'weight_decay': 0.02,\n",
    "                 'nhid': 45,\n",
    "                 'dropout_prob' : 0.6,\n",
    "                 'att_dropout_prob' : 0.9}\n",
    "\n",
    "learning_rate = search_params['learning_rate']\n",
    "weight_decay = search_params['weight_decay']\n",
    "nhid = search_params['nhid']\n",
    "dropout_prob = search_params['dropout_prob']\n",
    "att_dropout_prob = search_params['att_dropout_prob']\n",
    "\n",
    "# load the data to device\n",
    "\n",
    "edge_index = edge_index.to(device)\n",
    "\n",
    "# create result matrices\n",
    "num_epochs = 200\n",
    "num_reps = 1\n",
    "epoch_loss = dict()\n",
    "epoch_acc = dict()\n",
    "epoch_loss['train_mask'] = np.zeros((num_reps, num_epochs))\n",
    "epoch_acc['train_mask'] = np.zeros((num_reps, num_epochs))\n",
    "epoch_loss['val_mask'] = np.zeros((num_reps, num_epochs))\n",
    "epoch_acc['val_mask'] = np.zeros((num_reps, num_epochs))\n",
    "epoch_loss['test_mask'] = np.zeros((num_reps, num_epochs))\n",
    "epoch_acc['test_mask'] = np.zeros((num_reps, num_epochs))\n",
    "saved_model_val_acc = np.zeros(num_reps)\n",
    "saved_model_test_acc = np.zeros(num_reps)\n",
    "\n",
    "# initialize the learning rate scheduler\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "# training\n",
    "for rep in range(num_reps):\n",
    "    print('****** Rep {}: training start ******'.format(rep + 1))\n",
    "    max_acc = 0.0\n",
    "\n",
    "    # initialize the model\n",
    "    model = Net(dataset.num_node_features, nhid, dataset.num_classes, r, Lev, num_nodes, shrinkage=None,\n",
    "                threshold=1e-3, dropout_prob=dropout_prob).float().to(device)\n",
    "\n",
    "    # initialize the optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # training mode\n",
    "        epoch_loss = train(model, x.float(), edge_index, y_true.float(), train_idx, optimizer, d_list)\n",
    "        print('Epoch {}, training loss {:.4f}'.format(epoch, epoch_loss))\n",
    "\n",
    "        # evaluation mode\n",
    "        result = test(model, x.float(), edge_index, y_true.float(), split_idx, evaluator)\n",
    "        print(result)\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
